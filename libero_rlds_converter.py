# -*- coding: utf-8 -*-
"""
Liberoç»Ÿä¸€æ•°æ®è½¬æ¢å™¨

æ”¯æŒè‡ªåŠ¨è¯†åˆ«RLDSå’ŒHDF5æ ¼å¼ï¼Œè‡ªåŠ¨è§£ææˆLeRobotDataSetæ ¼å¼ï¼Œæ”¯æŒå¤šçº¿ç¨‹æ“ä½œ
"""

import argparse
import ast
import json
import logging
import shutil
import os
from pathlib import Path
from typing import Dict, Any, Optional, List, Union, Callable, Tuple
import concurrent.futures
from functools import partial
import multiprocessing
import sys

import cv2
import h5py
import numpy as np
from tqdm import tqdm

# æ£€æŸ¥ä¾èµ–
try:
    import tensorflow_datasets as tfds
    import tensorflow as tf
    HAS_TF = True
except ImportError:
    HAS_TF = False
    logging.warning("tensorflow_datasetsæœªå®‰è£…ï¼ŒRLDSæ”¯æŒå°†è¢«ç¦ç”¨")

try:
    from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
    # from lerobot.common.constants import HF_LEROBOT_HOME
except ImportError:
    from lerobot.datasets.lerobot_dataset import LeRobotDataset
    # from lerobot.constants import HF_LEROBOT_HOME


# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] [%(processName)s:%(process)d] [%(filename)s:%(lineno)d] %(message)s",
    handlers=[logging.StreamHandler()],
)
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
# ä»»åŠ¡åç§°å¸¸é‡
TASK_NAME = "Isaac-Stack-Cube-Franka-IK-Rel-Visuomotor-Cosmos-v0"

logger.info("Libero RLDS/HDF5è½¬æ¢å™¨åˆå§‹åŒ–")



class DatasetFormatDetector:
    """æ•°æ®é›†æ ¼å¼æ£€æµ‹å™¨"""
    
    @staticmethod
    def detect_format(data_path: Union[str, Path]) -> str:
        """
        è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†æ ¼å¼
        
        Args:
            data_path: æ•°æ®é›†è·¯å¾„
            
        Returns:
            str: 'rlds' æˆ– 'hdf5'
        """
        data_path = Path(data_path)
        
        # æ£€æŸ¥HDF5æ ¼å¼ï¼šæŸ¥æ‰¾.hdf5æˆ–.h5æ–‡ä»¶
        hdf5_files = list(data_path.rglob("*.hdf5")) + list(data_path.rglob("*.h5"))
        
        # æ£€æŸ¥RLDSæ ¼å¼ï¼šæŸ¥æ‰¾tfrecordæ–‡ä»¶æˆ–dataset_info.json
        rlds_indicators = (
            list(data_path.rglob("*.tfrecord*")) + 
            list(data_path.rglob("dataset_info.json")) +
            list(data_path.rglob("features.json"))
        )
        
        if hdf5_files and not rlds_indicators:
            logger.info(f"æ£€æµ‹åˆ°HDF5æ ¼å¼ï¼Œæ‰¾åˆ°{len(hdf5_files)}ä¸ªHDF5æ–‡ä»¶")
            return "hdf5"
        elif rlds_indicators and not hdf5_files:
            logger.info(f"æ£€æµ‹åˆ°RLDSæ ¼å¼ï¼Œæ‰¾åˆ°ç›¸å…³æ–‡ä»¶ï¼š"
                       f"{[f.name for f in rlds_indicators[:3]]}")
            return "rlds"
        elif hdf5_files and rlds_indicators:
            logger.warning("åŒæ—¶å‘ç°HDF5å’ŒRLDSæ–‡ä»¶ï¼Œä¼˜å…ˆä½¿ç”¨HDF5æ ¼å¼")
            return "hdf5"
        else:
            raise ValueError(f"æ— æ³•æ£€æµ‹æ•°æ®æ ¼å¼ï¼š{data_path}")


class HDF5Processor:
    """HDF5æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, image_size: Tuple[int, int] = (256, 256), 
                 use_videos: bool = False):
        """
        åˆå§‹åŒ–HDF5å¤„ç†å™¨
        
        Args:
            image_size: å›¾åƒå°ºå¯¸ (height, width) - åŒ¹é…numpyæ•°ç»„æ ¼å¼
            use_videos: æ˜¯å¦ä½¿ç”¨è§†é¢‘æ ¼å¼
        """
        self.image_size = image_size  # (height, width)
        self.use_videos = use_videos
    
    def get_default_features(self, use_videos: bool = True) -> Dict[str, Dict[str, Any]]:
        """è·å–Liberoæ•°æ®é›†çš„é»˜è®¤ç‰¹å¾é…ç½®"""
        image_dtype = "video" if use_videos else "image"

        return {
            "observation.images.front": {
                "dtype": image_dtype,
                "shape": (*self.image_size, 3),
                "names": ["height", "width", "channel"],
            },
            "observation.images.wrist": {
                "dtype": image_dtype,
                "shape": (*self.image_size, 3),
                "names": ["height", "width", "channel"],
            },
            "observation.state": {
                "dtype": "float32",
                "shape": (8,),
                "names": [f"state_{i}" for i in range(8)],
            },
            "action": {
                "dtype": "float32",
                "shape": (7,),
                "names": [f"action_{i}" for i in range(7)],
            },
            }
    
    def process_episode(self, episode_path: Path, dataset: LeRobotDataset, task_name: str) -> bool:
        """
        å¤„ç†å•ä¸ªepisodeæ•°æ®
        
        Args:
            episode_path: episodeæ–‡ä»¶è·¯å¾„
            dataset: LeRobotæ•°æ®é›†
            task_name: ä»»åŠ¡åç§°ï¼ˆå·²å¼ƒç”¨ï¼Œç°åœ¨ä½¿ç”¨TASK_NAMEå¸¸é‡ï¼‰
            
        Returns:
            bool: å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            with h5py.File(episode_path, "r") as file:
                logger.debug(f"HDF5æ–‡ä»¶é”®: {list(file.keys())}")
                
                # æ£€æµ‹HDF5æ–‡ä»¶æ ¼å¼ï¼Œæ”¯æŒå¤šç§Liberoæ ¼å¼
                if "data" in file:
                    # æ–°çš„Liberoæ ¼å¼ï¼šdata/demo_N/...
                    return self._process_libero_demo_format(file, dataset, task_name, episode_path)
                else:
                    logger.warning(f"æœªè¯†åˆ«çš„HDF5æ ¼å¼: {episode_path}")
                    return False

        except (FileNotFoundError, OSError, KeyError) as e:
            logger.error(f"è·³è¿‡ {episode_path}: {str(e)}")
            return False
            

    def _process_libero_demo_format(self, file: h5py.File, dataset: LeRobotDataset, task_name: str, file_path: Optional[Path] = None) -> bool:
        """å¤„ç†æ–°çš„Libero demoæ ¼å¼ï¼šdata/demo_N/..."""
        # æ³¨æ„ï¼štask_nameå‚æ•°å·²å¼ƒç”¨ï¼Œç°åœ¨ä½¿ç”¨TASK_NAMEå¸¸é‡
        data_group = file["data"]
        
        # ä½¿ç”¨å¸¸é‡ä»»åŠ¡åç§°
        task_str = TASK_NAME
        
        # è·å–æ‰€æœ‰demo
        demo_keys = [k for k in data_group.keys() if k.startswith("demo_")]
        demo_keys.sort(key=lambda x: int(x.split("_")[1]))  # æŒ‰æ•°å­—æ’åº
        
        for demo_key in demo_keys:
            demo_group = data_group[demo_key]
            logger.info(f"å¤„ç† {demo_key}")
            
            # ä½¿ç”¨å¸¸é‡ä»»åŠ¡åç§°
            demo_task_str = TASK_NAME
            
            # è¯»å–åŠ¨ä½œæ•°æ®
            actions = np.array(demo_group["actions"])
            
            # è¯»å–è§‚å¯Ÿæ•°æ®
            obs_group = demo_group["obs"]
            
            # è¯»å–å…³èŠ‚çŠ¶æ€ - ä½œä¸ºobservation.state
            # å°è¯•å¤šç§å¯èƒ½çš„å…³èŠ‚çŠ¶æ€å­—æ®µå
            if "joint_states" in obs_group:
                joint_states = np.array(obs_group["joint_states"])
            elif "joint_pos" in obs_group:
                joint_states = np.array(obs_group["joint_pos"])
            else:
                raise KeyError("æœªæ‰¾åˆ°å…³èŠ‚çŠ¶æ€æ•°æ® (joint_states æˆ– joint_pos)")
            
            # è°ƒæ•´çŠ¶æ€ç»´åº¦ä»¥åŒ¹é…RLDSæ ¼å¼
            if joint_states.shape[-1] == 7:
                # æ·»åŠ ä¸€ä¸ªé¢å¤–çš„ç»´åº¦ï¼ˆä¾‹å¦‚å¤¹çˆªçŠ¶æ€ï¼Œè®¾ä¸º0ï¼‰
                gripper_state = np.zeros((joint_states.shape[0], 1), dtype=joint_states.dtype)
                joint_states = np.concatenate([joint_states, gripper_state], axis=-1)
            elif joint_states.shape[-1] == 9:
                # å¦‚æœæ˜¯9ç»´ï¼Œå–å‰7ç»´ä½œä¸ºå…³èŠ‚ä½ç½®ï¼Œå2ç»´å¯èƒ½æ˜¯å¤¹çˆªçŠ¶æ€
                # æˆ‘ä»¬å–å‰7ç»´ï¼Œç„¶åæ·»åŠ ä¸€ä¸ªé¢å¤–çš„ç»´åº¦
                joint_states = joint_states[:, :7]
                gripper_state = np.zeros((joint_states.shape[0], 1), dtype=joint_states.dtype)
                joint_states = np.concatenate([joint_states, gripper_state], axis=-1)
            
            # è¯»å–å›¾åƒæ•°æ® - å°è¯•å¤šç§å¯èƒ½çš„å­—æ®µå
            if "agentview_rgb" in obs_group and "eye_in_hand_rgb" in obs_group:
                agentview_rgb = np.array(obs_group["agentview_rgb"])  # å‰è§†å›¾åƒ
                eye_in_hand_rgb = np.array(obs_group["eye_in_hand_rgb"])  # è…•éƒ¨å›¾åƒ
            elif "table_cam" in obs_group and "wrist_cam" in obs_group:
                agentview_rgb = np.array(obs_group["table_cam"])  # å‰è§†å›¾åƒ
                eye_in_hand_rgb = np.array(obs_group["wrist_cam"])  # è…•éƒ¨å›¾åƒ
            else:
                raise KeyError("æœªæ‰¾åˆ°å›¾åƒæ•°æ® (agentview_rgb/eye_in_hand_rgb æˆ– table_cam/wrist_cam)")
            
            # ç¡®ä¿æ‰€æœ‰æ•°ç»„é•¿åº¦ä¸€è‡´
            num_frames = min(len(actions), len(joint_states), len(agentview_rgb), len(eye_in_hand_rgb))
            
            # å¤„ç†æ¯ä¸€å¸§
            for i in tqdm(range(num_frames), desc=f"å¤„ç† {demo_key}", leave=False):
                # å¤„ç†å›¾åƒï¼šè°ƒæ•´å¤§å°åˆ°ç›®æ ‡å°ºå¯¸
                front_img = cv2.resize(agentview_rgb[i], (self.image_size[1], self.image_size[0]))
                wrist_img = cv2.resize(eye_in_hand_rgb[i], (self.image_size[1], self.image_size[0]))
                
                # ä¿®å¤å›¾åƒæ—‹è½¬é—®é¢˜ï¼šç¿»è½¬180åº¦
                front_img = cv2.flip(front_img, -1)  # -1è¡¨ç¤º180åº¦ç¿»è½¬
                wrist_img = cv2.flip(wrist_img, -1)  # -1è¡¨ç¤º180åº¦ç¿»è½¬
                
                # å‡†å¤‡å¸§æ•°æ® - å‚è€ƒRLDSæ ¼å¼
                frame_data = {
                    "action": actions[i].astype(np.float32),
                    "observation.state": joint_states[i].astype(np.float32),
                    "observation.images.front": front_img,
                    "observation.images.wrist": wrist_img,
                    "task": demo_task_str,
                }
                
                # æ·»åŠ å¸§åˆ°æ•°æ®é›† - ä¿®å¤APIè°ƒç”¨
                logger.debug(f"Adding frame with keys: {frame_data.keys()}")
                dataset.add_frame(frame_data)
            
            # æ¯ä¸ªdemoä¿å­˜ä¸ºä¸€ä¸ªepisode
            dataset.save_episode()
        
        return True


    def _extract_libero_demo_frames(self, file: h5py.File, task_name: str, file_path: Optional[Path] = None) -> List[List[Dict]]:
        """æå–Libero demoæ ¼å¼çš„å¸§æ•°æ®ï¼ˆç”¨äºå¤šçº¿ç¨‹å¤„ç†ï¼‰- è¿”å›æŒ‰demoåˆ†ç»„çš„æ•°æ®"""
        # æ³¨æ„ï¼štask_nameå‚æ•°å·²å¼ƒç”¨ï¼Œç°åœ¨ä½¿ç”¨TASK_NAMEå¸¸é‡
        demos_frames = []
        data_group = file["data"]
        
        # ä½¿ç”¨å¸¸é‡ä»»åŠ¡åç§°
        task_str = TASK_NAME
        
        # è·å–æ‰€æœ‰demo
        demo_keys = [k for k in data_group.keys() if k.startswith("demo_")]
        demo_keys.sort(key=lambda x: int(x.split("_")[1]))  # æŒ‰æ•°å­—æ’åº
        
        for demo_key in demo_keys:
            demo_frames = []
            demo_group = data_group[demo_key]
            
            # ä½¿ç”¨å¸¸é‡ä»»åŠ¡åç§°
            demo_task_str = TASK_NAME
            
            # è¯»å–åŠ¨ä½œæ•°æ®
            actions = np.array(demo_group["actions"])
            
            # è¯»å–è§‚å¯Ÿæ•°æ®
            obs_group = demo_group["obs"]
            
            # è¯»å–å…³èŠ‚çŠ¶æ€ - ä½œä¸ºobservation.state
            # å°è¯•å¤šç§å¯èƒ½çš„å…³èŠ‚çŠ¶æ€å­—æ®µå
            if "joint_states" in obs_group:
                joint_states = np.array(obs_group["joint_states"])
            elif "joint_pos" in obs_group:
                joint_states = np.array(obs_group["joint_pos"])
            else:
                raise KeyError("æœªæ‰¾åˆ°å…³èŠ‚çŠ¶æ€æ•°æ® (joint_states æˆ– joint_pos)")
            
            # è°ƒæ•´çŠ¶æ€ç»´åº¦ä»¥åŒ¹é…RLDSæ ¼å¼
            if joint_states.shape[-1] == 7:
                # æ·»åŠ ä¸€ä¸ªé¢å¤–çš„ç»´åº¦ï¼ˆä¾‹å¦‚å¤¹çˆªçŠ¶æ€ï¼Œè®¾ä¸º0ï¼‰
                gripper_state = np.zeros((joint_states.shape[0], 1), dtype=joint_states.dtype)
                joint_states = np.concatenate([joint_states, gripper_state], axis=-1)
            elif joint_states.shape[-1] == 9:
                # å¦‚æœæ˜¯9ç»´ï¼Œå–å‰7ç»´ä½œä¸ºå…³èŠ‚ä½ç½®ï¼Œå2ç»´å¯èƒ½æ˜¯å¤¹çˆªçŠ¶æ€
                # æˆ‘ä»¬å–å‰7ç»´ï¼Œç„¶åæ·»åŠ ä¸€ä¸ªé¢å¤–çš„ç»´åº¦
                joint_states = joint_states[:, :7]
                gripper_state = np.zeros((joint_states.shape[0], 1), dtype=joint_states.dtype)
                joint_states = np.concatenate([joint_states, gripper_state], axis=-1)
            
            # è¯»å–å›¾åƒæ•°æ® - å°è¯•å¤šç§å¯èƒ½çš„å­—æ®µå
            if "agentview_rgb" in obs_group and "eye_in_hand_rgb" in obs_group:
                agentview_rgb = np.array(obs_group["agentview_rgb"])  # å‰è§†å›¾åƒ
                eye_in_hand_rgb = np.array(obs_group["eye_in_hand_rgb"])  # è…•éƒ¨å›¾åƒ
            elif "table_cam" in obs_group and "wrist_cam" in obs_group:
                agentview_rgb = np.array(obs_group["table_cam"])  # å‰è§†å›¾åƒ
                eye_in_hand_rgb = np.array(obs_group["wrist_cam"])  # è…•éƒ¨å›¾åƒ
            else:
                raise KeyError("æœªæ‰¾åˆ°å›¾åƒæ•°æ® (agentview_rgb/eye_in_hand_rgb æˆ– table_cam/wrist_cam)")
            
            # ç¡®ä¿æ‰€æœ‰æ•°ç»„é•¿åº¦ä¸€è‡´
            num_frames = min(len(actions), len(joint_states), len(agentview_rgb), len(eye_in_hand_rgb))
            
            # å¤„ç†æ¯ä¸€å¸§
            for i in range(num_frames):
                # å¤„ç†å›¾åƒï¼šè°ƒæ•´å¤§å°åˆ°ç›®æ ‡å°ºå¯¸
                front_img = cv2.resize(agentview_rgb[i], (self.image_size[1], self.image_size[0]))
                wrist_img = cv2.resize(eye_in_hand_rgb[i], (self.image_size[1], self.image_size[0]))
                
                # ä¿®å¤å›¾åƒæ—‹è½¬é—®é¢˜ï¼šç¿»è½¬180åº¦
                front_img = cv2.flip(front_img, -1)  # -1è¡¨ç¤º180åº¦ç¿»è½¬
                wrist_img = cv2.flip(wrist_img, -1)  # -1è¡¨ç¤º180åº¦ç¿»è½¬
                
                # å‡†å¤‡å¸§æ•°æ® - å‚è€ƒRLDSæ ¼å¼
                frame_data = {
                    "action": actions[i].astype(np.float32),
                    "observation.state": joint_states[i].astype(np.float32),
                    "observation.images.front": front_img,
                    "observation.images.wrist": wrist_img,
                    "task": demo_task_str,
                }
                demo_frames.append(frame_data)
            
            demos_frames.append(demo_frames)
        
        return demos_frames

    def _extract_direct_episode_frames(self, file: h5py.File, task_name: str, file_path: Optional[Path] = None) -> List[List[Dict]]:
        """æå–ç›´æ¥episodeæ ¼å¼çš„å¸§æ•°æ®ï¼ˆå…œåº•æ–¹æ¡ˆï¼Œç”¨äºå¤šçº¿ç¨‹å¤„ç†ï¼‰- è¿”å›æŒ‰episodeåˆ†ç»„çš„æ•°æ®"""
        # æ³¨æ„ï¼štask_nameå‚æ•°å·²å¼ƒç”¨ï¼Œç°åœ¨ä½¿ç”¨TASK_NAMEå¸¸é‡
        # å…œåº•æ–¹æ¡ˆï¼šå°†æ•´ä¸ªæ–‡ä»¶ä½œä¸ºä¸€ä¸ªepisode
        episode_frames = []
        
        # ä½¿ç”¨å¸¸é‡ä»»åŠ¡åç§°
        task_str = TASK_NAME
        
        # å°è¯•æ‰¾åˆ°å¯èƒ½çš„çŠ¶æ€æ•°æ®
        state_keys = ["joint_states", "joint_pos", "states", "robot_states", "state"]
        state_data = None
        
        for key in state_keys:
            if key in file:
                state_data = np.array(file[key])
                logger.info(f"æ‰¾åˆ°çŠ¶æ€æ•°æ®: {key}, shape: {state_data.shape}")
                break
        
        if state_data is None:
            raise KeyError("æœªæ‰¾åˆ°ä»»ä½•çŠ¶æ€æ•°æ®")
        
        # è°ƒæ•´çŠ¶æ€ç»´åº¦ä»¥åŒ¹é…RLDSæ ¼å¼
        if state_data.shape[-1] == 7:
            # æ·»åŠ ä¸€ä¸ªé¢å¤–çš„ç»´åº¦ï¼ˆä¾‹å¦‚å¤¹çˆªçŠ¶æ€ï¼Œè®¾ä¸º0ï¼‰
            gripper_state = np.zeros((state_data.shape[0], 1), dtype=state_data.dtype)
            state_data = np.concatenate([state_data, gripper_state], axis=-1)
            logger.info(f"çŠ¶æ€æ•°æ®ä»7ç»´æ‰©å±•ä¸º8ç»´: {state_data.shape}")
        elif state_data.shape[-1] == 9:
            # å¦‚æœæ˜¯9ç»´ï¼Œå–å‰7ç»´ä½œä¸ºå…³èŠ‚ä½ç½®ï¼Œå2ç»´å¯èƒ½æ˜¯å¤¹çˆªçŠ¶æ€
            # æˆ‘ä»¬å–å‰7ç»´ï¼Œç„¶åæ·»åŠ ä¸€ä¸ªé¢å¤–çš„ç»´åº¦
            state_data = state_data[:, :7]
            gripper_state = np.zeros((state_data.shape[0], 1), dtype=state_data.dtype)
            state_data = np.concatenate([state_data, gripper_state], axis=-1)
            logger.info(f"çŠ¶æ€æ•°æ®ä»9ç»´è°ƒæ•´ä¸º8ç»´: {state_data.shape}")
        
        # å°è¯•æ‰¾åˆ°åŠ¨ä½œæ•°æ®
        action_keys = ["actions", "action"]
        action_data = None
        
        for key in action_keys:
            if key in file:
                action_data = np.array(file[key])
                break
        
        if action_data is None:
            logger.warning("æœªæ‰¾åˆ°åŠ¨ä½œæ•°æ®ï¼Œä½¿ç”¨çŠ¶æ€æ•°æ®ä½œä¸ºåŠ¨ä½œ")
            action_data = state_data
        
        # å°è¯•æ‰¾åˆ°å›¾åƒæ•°æ®
        image_keys = ["agentview_rgb", "table_cam", "images", "rgb"]
        front_image_data = None
        wrist_image_data = None
        
        # å…ˆå°è¯•æ‰¾åˆ°å‰è§†å›¾åƒ
        for key in image_keys:
            if key in file:
                front_image_data = np.array(file[key])
                logger.info(f"æ‰¾åˆ°å‰è§†å›¾åƒæ•°æ®: {key}, shape: {front_image_data.shape}")
                break
        
        # å°è¯•æ‰¾åˆ°è…•éƒ¨å›¾åƒ
        wrist_image_keys = ["eye_in_hand_rgb", "wrist_cam"]
        for key in wrist_image_keys:
            if key in file:
                wrist_image_data = np.array(file[key])
                logger.info(f"æ‰¾åˆ°è…•éƒ¨å›¾åƒæ•°æ®: {key}, shape: {wrist_image_data.shape}")
                break
        
        # å¦‚æœåªæ‰¾åˆ°ä¸€ç§å›¾åƒï¼Œåˆ™å¤åˆ¶ä½¿ç”¨
        if front_image_data is not None and wrist_image_data is None:
            wrist_image_data = front_image_data
            logger.info("æœªæ‰¾åˆ°è…•éƒ¨å›¾åƒï¼Œä½¿ç”¨å‰è§†å›¾åƒä½œä¸ºè…•éƒ¨å›¾åƒ")
        elif front_image_data is None and wrist_image_data is not None:
            front_image_data = wrist_image_data
            logger.info("æœªæ‰¾åˆ°å‰è§†å›¾åƒï¼Œä½¿ç”¨è…•éƒ¨å›¾åƒä½œä¸ºå‰è§†å›¾åƒ")
        elif front_image_data is None and wrist_image_data is None:
            logger.warning("æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ•°æ®ï¼Œå°†åˆ›å»ºç©ºå›¾åƒ")
            front_image_data = np.zeros((len(state_data), *self.image_size, 3), dtype=np.uint8)
            wrist_image_data = np.zeros((len(state_data), *self.image_size, 3), dtype=np.uint8)
        
        # ç¡®ä¿æ‰€æœ‰æ•°ç»„é•¿åº¦ä¸€è‡´
        num_frames = min(len(state_data), len(action_data), len(front_image_data), len(wrist_image_data))
        
        # å¤„ç†æ¯ä¸€å¸§
        for i in range(num_frames):
            # å¤„ç†å‰è§†å›¾åƒ
            if front_image_data.ndim == 4:  # æœ‰æ—¶é—´ç»´åº¦
                front_img = cv2.resize(front_image_data[i], (self.image_size[1], self.image_size[0]))
            else:  # æ²¡æœ‰æ—¶é—´ç»´åº¦ï¼Œä½¿ç”¨ç¬¬ä¸€å¼ å›¾
                if len(front_image_data) > 0:
                    front_img = cv2.resize(front_image_data[0],
                                   (self.image_size[1], self.image_size[0]))
                else:
                    front_img = np.zeros((*self.image_size, 3), dtype=np.uint8)
            
            # å¤„ç†è…•éƒ¨å›¾åƒ
            if wrist_image_data.ndim == 4:  # æœ‰æ—¶é—´ç»´åº¦
                wrist_img = cv2.resize(wrist_image_data[i], (self.image_size[1], self.image_size[0]))
            else:  # æ²¡æœ‰æ—¶é—´ç»´åº¦ï¼Œä½¿ç”¨ç¬¬ä¸€å¼ å›¾
                if len(wrist_image_data) > 0:
                    wrist_img = cv2.resize(wrist_image_data[0],
                                   (self.image_size[1], self.image_size[0]))
                else:
                    wrist_img = np.zeros((*self.image_size, 3), dtype=np.uint8)
            
            # ä¿®å¤å›¾åƒæ—‹è½¬é—®é¢˜ï¼šç¿»è½¬180åº¦
            front_img = cv2.flip(front_img, -1)  # -1è¡¨ç¤º180åº¦ç¿»è½¬
            wrist_img = cv2.flip(wrist_img, -1)  # -1è¡¨ç¤º180åº¦ç¿»è½¬
            
            frame_data = {
                "action": action_data[i].astype(np.float32),
                "observation.state": state_data[i].astype(np.float32),
                "observation.images.front": front_img,
                "observation.images.wrist": wrist_img,
                "task": task_str,
            }
            episode_frames.append(frame_data)
        
        return [episode_frames]  # è¿”å›å•ä¸ªepisodeçš„åˆ—è¡¨


class RLDSProcessor:
    """RLDSæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self):
        if not HAS_TF:
            raise ImportError("tensorflow_datasetsæ˜¯RLDSå¤„ç†æ‰€å¿…éœ€çš„ï¼Œè¯·è¿è¡Œ: pip install tensorflow tensorflow_datasets")
        # æ·»åŠ ä¸HDF5Processorå…¼å®¹çš„å±æ€§
        self.image_size = (256, 256)
        self.use_videos = False
    
    def get_default_features(self, use_videos: bool = True) -> Dict[str, Dict[str, Any]]:
        """è·å–Liberoæ•°æ®é›†çš„é»˜è®¤ç‰¹å¾é…ç½®"""
        image_dtype = "video" if use_videos else "image"

        return {
            "observation.images.front": {
                "dtype": image_dtype,
                "shape": (256, 256, 3),
                "names": ["height", "width", "channel"],
            },
            "observation.images.wrist": {
                "dtype": image_dtype,
                "shape": (256, 256, 3),
                "names": ["height", "width", "channel"],
            },
            "observation.state": {
                "dtype": "float32",
                "shape": (8,),
                "names": [f"state_{i}" for i in range(8)],
            },
            "action": {
                "dtype": "float32",
                "shape": (7,),
                "names": [f"action_{i}" for i in range(7)],
            },
            }
    
    def process_dataset(self, dataset: LeRobotDataset, data_source: Union[str, Path]):
        """å¤„ç†RLDSæ•°æ®é›†"""
        # Liberoæ•°æ®é›†åç§°åˆ—è¡¨ã€‚æ ¹æ®è‡ªå·±éœ€æ±‚ä¿®æ”¹
        raw_dataset_names = [
            "libero_10_no_noops",
            "libero_goal_no_noops", 
            "libero_object_no_noops",
            "libero_spatial_no_noops",
        ]
        
        episode_idx = 0
        
        for raw_dataset_name in raw_dataset_names:
            logger.info(f"å¤„ç†RLDSæ•°æ®é›†: {raw_dataset_name}")
            
            try:
                # åŠ è½½RLDSæ•°æ®é›†
                raw_dataset = tfds.load(
                    raw_dataset_name, 
                    data_dir=data_source, 
                    split="train",
                    try_gcs=False
                )
                
                for episode in raw_dataset:
                    logger.info(f"å¤„ç†episode {episode_idx + 1}")
                    
                    # è·å–ä»»åŠ¡æè¿°
                    steps_list = list(episode["steps"].as_numpy_iterator())
                    task_str = f"episode_{episode_idx}"
                    
                    if steps_list and "language_instruction" in steps_list[0]:
                        task_str = steps_list[0]["language_instruction"].decode()
                    
                    # å¤„ç†episodeä¸­çš„æ¯ä¸ªstep
                    for step_idx, step in enumerate(steps_list):
                        frame_data = {
                            "observation.images.front": step["observation"]["image"],
                            "observation.images.wrist": step["observation"]["wrist_image"],
                            "observation.state": step["observation"]["state"].astype(np.float32),
                            "action": step["action"].astype(np.float32),
                            "task": task_str,
                        }
                        # ä¿®å¤APIè°ƒç”¨
                        dataset.add_frame(frame_data)
                    
                    dataset.save_episode()
                    episode_idx += 1
                    
            except Exception as e:
                logger.warning(f"å¤„ç†æ•°æ®é›† {raw_dataset_name} æ—¶å‡ºé”™: {e}")
                continue


class UnifiedConverter:
    """ç»Ÿä¸€è½¬æ¢å™¨ç±»"""
    
    def __init__(self, num_workers: int = 4):
        """
        åˆå§‹åŒ–ç»Ÿä¸€è½¬æ¢å™¨
        
        Args:
            num_workers: å¹¶è¡Œå¤„ç†çš„å·¥ä½œçº¿ç¨‹æ•°
        """
        self.num_workers = num_workers
        self.detector = DatasetFormatDetector()
        
        # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•ï¼Œæé«˜Python 3.14å…¼å®¹æ€§
        try:
            if sys.version_info >= (3, 14) and num_workers > 1:
                logger.warning("Python 3.14+æ£€æµ‹åˆ°ï¼Œå»ºè®®ä½¿ç”¨--num-workers 1ä»¥é¿å…pickleå…¼å®¹æ€§é—®é¢˜")
            # å°è¯•è®¾ç½®æ›´å®‰å…¨çš„å¯åŠ¨æ–¹æ³•
            if hasattr(multiprocessing, 'get_start_method'):
                current_method = multiprocessing.get_start_method()
                if current_method != 'spawn':
                    try:
                        multiprocessing.set_start_method('spawn', force=True)
                        logger.info(f"å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•ä» {current_method} æ›´æ”¹ä¸º spawn")
                    except RuntimeError:
                        # å¦‚æœå·²ç»è®¾ç½®è¿‡ï¼Œæ— æ³•å†æ¬¡è®¾ç½®
                        logger.debug(f"æ— æ³•æ›´æ”¹å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•ï¼Œä½¿ç”¨å½“å‰æ–¹æ³•: {current_method}")
        except Exception as e:
            logger.warning(f"è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•æ—¶å‡ºé”™: {e}")
    
    def convert_dataset(
        self,
        data_dir: Union[str, Path],
        repo_id: str,
        output_dir: Optional[Union[str, Path]] = None,
        push_to_hub: bool = False,
        use_videos: bool = True,
        robot_type: str = "panda",
        fps: int = 20,
        task_name: str = "default_task",  # å·²å¼ƒç”¨ï¼Œç°åœ¨ä½¿ç”¨TASK_NAMEå¸¸é‡
        hub_config: Optional[Dict[str, Any]] = None,
        clean_existing: bool = True,
        image_writer_threads: int = 10,
        image_writer_processes: int = 5,
        run_compute_stats: bool = False,
        **kwargs
    ) -> LeRobotDataset:
        """
        ç»Ÿä¸€è½¬æ¢æ¥å£
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            repo_id: æ•°æ®é›†ä»“åº“ID
            output_dir: è¾“å‡ºç›®å½•
            push_to_hub: æ˜¯å¦æ¨é€åˆ°Hub
            use_videos: æ˜¯å¦ä½¿ç”¨è§†é¢‘æ ¼å¼
            robot_type: æœºå™¨äººç±»å‹
            fps: å¸§ç‡
            task_name: ä»»åŠ¡åç§°ï¼ˆå·²å¼ƒç”¨ï¼Œç°åœ¨ä½¿ç”¨TASK_NAMEå¸¸é‡ï¼‰
            hub_config: Hubé…ç½®
            clean_existing: æ˜¯å¦æ¸…ç†ç°æœ‰æ•°æ®é›†
            image_writer_threads: å›¾åƒå†™å…¥çº¿ç¨‹æ•°
            image_writer_processes: å›¾åƒå†™å…¥è¿›ç¨‹æ•°
            run_compute_stats: æ˜¯å¦è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            
        Returns:
            LeRobotDataset: è½¬æ¢åçš„æ•°æ®é›†
        """
        data_path = Path(data_dir)
        
        # è‡ªåŠ¨æ£€æµ‹æ ¼å¼
        format_type = self.detector.detect_format(data_path)
        logger.info(f"æ£€æµ‹åˆ°æ•°æ®æ ¼å¼: {format_type}")
        
        # æ ¹æ®æ ¼å¼é€‰æ‹©å¤„ç†å™¨å’Œç‰¹å¾
        if format_type == "hdf5":
            processor = HDF5Processor()
            features = processor.get_default_features(use_videos)

        else:  # rlds
            processor = RLDSProcessor()
            features = processor.get_default_features(use_videos)
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        if output_dir is None:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºç›®å½•ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
            lerobot_root = Path("./outputs")
        else:
            lerobot_root = Path(output_dir)
        
        os.environ["HF_LEROBOT_HOME"] = str(lerobot_root)
        lerobot_dataset_dir = lerobot_root / repo_id
        
        # æ¸…ç†ç°æœ‰æ•°æ®é›†
        if clean_existing and lerobot_dataset_dir.exists():
            logger.info(f"æ¸…ç†ç°æœ‰æ•°æ®é›†: {lerobot_dataset_dir}")
            shutil.rmtree(lerobot_dataset_dir)
        
        lerobot_root.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºLeRobotæ•°æ®é›†
        logger.info(f"åˆ›å»ºLeRobotæ•°æ®é›†: {repo_id}")
        logger.info(f"æœºå™¨äººç±»å‹: {robot_type}, å¸§ç‡: {fps}, ä½¿ç”¨è§†é¢‘: {use_videos}")
        logger.info(f"å›¾åƒå†™å…¥è¿›ç¨‹æ•°: {image_writer_processes}, çº¿ç¨‹æ•°: {image_writer_threads}")
        logger.info(f"ç‰¹å¾é…ç½®: {features.keys()}")

        # å½“ä½¿ç”¨è§†é¢‘æ—¶ï¼Œä½¿ç”¨è¾ƒå°çš„æ‰¹å¤„ç†å¤§å°ä»¥å¹³è¡¡æ€§èƒ½å’Œå®‰å…¨æ€§
        batch_encoding_size = 10 if use_videos else 100
        logger.info(f"æ‰¹å¤„ç†ç¼–ç å¤§å°: {batch_encoding_size} (ä½¿ç”¨è¾ƒå°çš„æ‰¹å¤„ç†ä»¥é˜²æ­¢å†…å­˜é—®é¢˜)")

        dataset = LeRobotDataset.create(
            repo_id=repo_id,
            robot_type=robot_type,
            fps=fps,
            features=features,
            use_videos=use_videos,
            image_writer_processes=image_writer_processes,
            image_writer_threads=image_writer_threads,
            batch_encoding_size=batch_encoding_size,
        )
        
        # å¤„ç†æ•°æ®
        if format_type == "hdf5":
            self._process_hdf5_data(processor, dataset, data_path, TASK_NAME)
        else:  # rlds
            # ç¡®ä¿æ˜¯RLDSProcessorå®ä¾‹
            if isinstance(processor, RLDSProcessor):
                processor.process_dataset(dataset, data_path)
            else:
                raise TypeError("RLDSæ ¼å¼éœ€è¦RLDSProcessorå®ä¾‹")
        
        # ç§»é™¤consolidateè°ƒç”¨ï¼Œå› ä¸ºAPIå¯èƒ½å·²æ›´æ”¹
        logger.info("æ•°æ®é›†å¤„ç†å®Œæˆ")
        
        # æ¨é€åˆ°Hub
        if push_to_hub:
            if hub_config is None:
                hub_config = self._get_default_hub_config()
            logger.info("æ¨é€åˆ°Hugging Face Hub...")
            dataset.push_to_hub(**hub_config)
        
        logger.info("âœ… æ•°æ®é›†è½¬æ¢å®Œæˆ!")
        return dataset
    
    def _process_hdf5_data(self, processor: Union[HDF5Processor, RLDSProcessor], dataset: LeRobotDataset, data_path: Path, task_name: str):
        """ä½¿ç”¨å¤šçº¿ç¨‹å¤„ç†HDF5æ•°æ®"""
        # æ³¨æ„ï¼štask_nameå‚æ•°å·²å¼ƒç”¨ï¼Œç°åœ¨ä½¿ç”¨TASK_NAMEå¸¸é‡
        # ç¡®ä¿æ˜¯HDF5Processor
        if not isinstance(processor, HDF5Processor):
            raise TypeError("processorå¿…é¡»æ˜¯HDF5Processorå®ä¾‹")
            
        # æŸ¥æ‰¾æ‰€æœ‰episode
        episodes = []
        for ep_dir in data_path.iterdir():
            if ep_dir.is_dir():
                ep_path = ep_dir / "data" / "trajectory.hdf5"
                if ep_path.exists():
                    episodes.append(ep_path)
        
        if not episodes:
            # ç›´æ¥æŸ¥æ‰¾HDF5æ–‡ä»¶
            episodes = list(data_path.rglob("*.hdf5")) + list(data_path.rglob("*.h5"))
        
        logger.info(f"æ‰¾åˆ° {len(episodes)} ä¸ªepisodeæ–‡ä»¶")
        
        # æ£€æŸ¥Pythonç‰ˆæœ¬å’Œå¹¶è¡Œè®¾ç½®
        import sys
        use_parallel = self.num_workers > 1 and sys.version_info < (3, 14)
        
        if not use_parallel:
            # å•çº¿ç¨‹å¤„ç†ï¼ˆPython 3.14+æˆ–num_workers=1ï¼‰
            if sys.version_info >= (3, 14):
                logger.warning("æ£€æµ‹åˆ°Python 3.14+ï¼Œç”±äºpickleå…¼å®¹æ€§é—®é¢˜ï¼Œä½¿ç”¨é¡ºåºå¤„ç†è€Œéå¹¶è¡Œå¤„ç†")
            for ep_path in tqdm(episodes, desc="å¤„ç†Episodes"):
                processor.process_episode(ep_path, dataset, TASK_NAME)
                logger.info(f"å¤„ç†å®Œæˆ: {ep_path.name}")
        else:
            # å¤šçº¿ç¨‹å¤„ç†
            self._process_episodes_parallel(processor, dataset, episodes, TASK_NAME)
    
    def _process_episodes_parallel(self, processor: HDF5Processor, dataset: LeRobotDataset, episodes: List[Path], task_name: str):
        """å¹¶è¡Œå¤„ç†episodesï¼Œä½¿ç”¨HDF5Processorçš„ç»Ÿä¸€æ–¹æ³•"""
        # æ³¨æ„ï¼štask_nameå‚æ•°å·²å¼ƒç”¨ï¼Œç°åœ¨ä½¿ç”¨TASK_NAMEå¸¸é‡
        # æ£€æŸ¥Pythonç‰ˆæœ¬ï¼Œå¦‚æœæ˜¯3.14+åˆ™ä½¿ç”¨é¡ºåºå¤„ç†ä»¥é¿å…pickleé—®é¢˜
        import sys
        if sys.version_info >= (3, 14):
            logger.warning("æ£€æµ‹åˆ°Python 3.14+ï¼Œç”±äºpickleå…¼å®¹æ€§é—®é¢˜ï¼Œä½¿ç”¨é¡ºåºå¤„ç†è€Œéå¹¶è¡Œå¤„ç†")
            for ep_path in tqdm(episodes, desc="å¤„ç†Episodes"):
                processor.process_episode(ep_path, dataset, TASK_NAME)
                logger.info(f"å¤„ç†å®Œæˆ: {ep_path.name}")
            return
        
        # åˆ›å»ºå¤„ç†å‡½æ•°
        def process_single_episode(ep_path: Path) -> Tuple[Path, bool, List[List[Dict]]]:
            """å¤„ç†å•ä¸ªepisodeå¹¶è¿”å›å¸§æ•°æ®"""
            demos_frames = []
            try:
                with h5py.File(ep_path, "r") as file:
                    logger.debug(f"å¤šçº¿ç¨‹å¤„ç†HDF5æ–‡ä»¶é”®: {list(file.keys())}")
                    
                    # ä½¿ç”¨ä¸HDF5Processorç›¸åŒçš„æ£€æµ‹å’Œå¤„ç†é€»è¾‘
                    if "data" in file:
                        # æ–°çš„Liberoæ ¼å¼ï¼šdata/demo_N/...
                        demos_frames = processor._extract_libero_demo_frames(file, TASK_NAME, ep_path)
                    else:
                        # å°è¯•å…¶ä»–æ ¼å¼çš„å…œåº•å¤„ç†
                        demos_frames = processor._extract_direct_episode_frames(file, TASK_NAME, ep_path)
                    
                return ep_path, True, demos_frames
            except Exception as e:
                logger.error(f"å¤„ç† {ep_path} å¤±è´¥: {e}")
                return ep_path, False, []
        
        # å¹¶è¡Œå¤„ç†
        logger.info(f"ä½¿ç”¨ {self.num_workers} ä¸ªå·¥ä½œçº¿ç¨‹å¹¶è¡Œå¤„ç†episodes")
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.num_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_episode = {executor.submit(process_single_episode, ep): ep for ep in episodes}
            
            # æ”¶é›†ç»“æœ
            for future in tqdm(concurrent.futures.as_completed(future_to_episode), total=len(episodes), desc="å¤„ç†Episodes"):
                ep_path, success, demos_frames_list = future.result()
                
                if success and demos_frames_list:
                    # æ¯ä¸ªdemoä½œä¸ºç‹¬ç«‹çš„episodeä¿å­˜
                    for demo_idx, demo_frames in enumerate(demos_frames_list):
                        for frame_data in demo_frames:
                            # ä¸å†ç§»é™¤taskä¿¡æ¯ï¼Œç›´æ¥ä½¿ç”¨
                            dataset.add_frame(frame_data)
                        dataset.save_episode()
                        logger.info(f"ä¿å­˜episode: {ep_path.name}_demo_{demo_idx}")
    
    def _get_default_hub_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤Hubé…ç½®"""
        return {
            "tags": ["libero", "robotics", "lerobot", "unified"],
            "private": False,
            "push_videos": True,
            "license": "apache-2.0",
        }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Liberoç»Ÿä¸€æ•°æ®è½¬æ¢å™¨ - æ”¯æŒRLDSå’ŒHDF5æ ¼å¼è‡ªåŠ¨è¯†åˆ«",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # è‡ªåŠ¨æ£€æµ‹æ ¼å¼å¹¶è½¬æ¢
  python unified_converter.py \\
    --data-dir /path/to/data \\
    --repo-id username/dataset_name \\
    --push-to-hub \\
    --use-videos \\
    --num-workers 4

  # HDF5æ ¼å¼ï¼ŒæŒ‡å®šé…ç½®æ–‡ä»¶
  python unified_converter.py \\
    --data-dir /path/to/hdf5/data \\
    --repo-id username/hdf5_dataset \\
    --config config.json \\
    --task-name "pick_and_place" \\
    --num-workers 8
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument("--data-dir", type=str, required=True, help="æ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--repo-id", type=str, required=True, help="æ•°æ®é›†ä»“åº“ID")
    
    # è¾“å‡ºé…ç½®
    parser.add_argument("--output-dir", type=str, default=None, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--push-to-hub", action="store_true", help="æ¨é€åˆ°Hub")
    parser.add_argument("--private", action="store_true", help="åˆ›å»ºç§æœ‰æ•°æ®é›†")
    
    # æ•°æ®æ ¼å¼
    parser.add_argument("--use-videos", action="store_true", help="ä½¿ç”¨è§†é¢‘æ ¼å¼")
    parser.add_argument("--robot-type", type=str, default="panda", help="æœºå™¨äººç±»å‹")
    parser.add_argument("--fps", type=int, default=20, help="å¸§ç‡")
    
    # HDF5ç‰¹å®šå‚æ•°
    parser.add_argument("--task-name", type=str, default="default_task", help="ä»»åŠ¡åç§°")
    
    # æ€§èƒ½å‚æ•°
    parser.add_argument("--num-workers", type=int, default=2, help="å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°")
    parser.add_argument("--image-writer-processes", type=int, default=5, help="å›¾åƒå†™å…¥è¿›ç¨‹æ•°")
    parser.add_argument("--image-writer-threads", type=int, default=1, help="å›¾åƒå†™å…¥çº¿ç¨‹æ•°")
    
    # Hubé…ç½®
    parser.add_argument("--license", type=str, default="apache-2.0", help="æ•°æ®é›†è®¸å¯è¯")
    parser.add_argument("--tags", nargs="+", default=["libero", "robotics", "lerobot"], help="æ•°æ®é›†æ ‡ç­¾")
    
    # è°ƒè¯•é€‰é¡¹
    parser.add_argument("--verbose", action="store_true", help="è¯¦ç»†æ—¥å¿—")
    parser.add_argument("--dry-run", action="store_true", help="è¯•è¿è¡Œæ¨¡å¼")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # éªŒè¯å‚æ•°
    if not Path(args.data_dir).exists():
        logger.error(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {args.data_dir}")
        return 1
    
    if "/" not in args.repo_id:
        logger.error(f"repo_idæ ¼å¼é”™è¯¯: {args.repo_id}")
        return 1
    
    logger.info("ğŸ“‹ è½¬æ¢é…ç½®:")
    logger.info(f"  æ•°æ®æº: {args.data_dir}")
    logger.info(f"  ä»“åº“ID: {args.repo_id}")
    logger.info(f"  å¹¶è¡Œçº¿ç¨‹æ•°: {args.num_workers}")
    logger.info(f"  ä½¿ç”¨è§†é¢‘: {args.use_videos}")
    logger.info(f"  æ¨é€åˆ°Hub: {args.push_to_hub}")
    
    if args.dry_run:
        logger.info("âœ… è¯•è¿è¡Œå®Œæˆï¼Œå‚æ•°éªŒè¯é€šè¿‡")
        return 0
    
    # æ‰§è¡Œè½¬æ¢
    try:
        converter = UnifiedConverter(num_workers=args.num_workers)
        
        hub_config = {
            "tags": args.tags,
            "private": args.private,
            "license": args.license,
        }

        
        dataset = converter.convert_dataset(
            data_dir=args.data_dir,
            repo_id=args.repo_id,
            output_dir=args.output_dir,
            push_to_hub=args.push_to_hub,
            use_videos=args.use_videos,
            robot_type=args.robot_type,
            fps=args.fps,
            task_name=TASK_NAME,
            hub_config=hub_config,
            image_writer_processes=args.image_writer_processes,
            image_writer_threads=args.image_writer_threads,
        )
        
        logger.info("âœ… è½¬æ¢å®Œæˆ!")
        return 0
        
    except Exception as e:
        logger.error(f"è½¬æ¢å¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main()) 
